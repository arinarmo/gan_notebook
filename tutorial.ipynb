{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Qué es una GAN?\n",
    "\n",
    "![](img/gan_schema.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Networks\n",
    "\n",
    "![](img/conv.jpeg)\n",
    "\n",
    "![](img/conv.gif \"segment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DCGAN\n",
    "\n",
    "![](img/DCGAN.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torchvision.utils import make_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on GPU: GeForce MX150\n"
     ]
    }
   ],
   "source": [
    "# Check if torch is running on GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(\"Running on GPU: {}\".format(torch.cuda.get_device_name(0)))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get MNIST data\n",
    "IMAGE_SIZE = 64\n",
    "mnist_data = datasets.MNIST(\n",
    "    root='data/mnist/', \n",
    "    download=True,\n",
    "   transform=transforms.Compose([\n",
    "       transforms.Resize(IMAGE_SIZE),\n",
    "       transforms.ToTensor(),\n",
    "       transforms.Normalize((0.5,), (0.5,))\n",
    "   ])\n",
    ")\n",
    "img_channels = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at it!\n",
    "def show_tensor_imgs(tensor, **kwargs):\n",
    "    grid = np.transpose(make_grid(tensor, **kwargs).cpu(), (1,2,0))\n",
    "    plt.imshow(grid)\n",
    "    \n",
    "show_tensor_imgs(mnist_data.data[0:25].unsqueeze(1), nrow=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator Network\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_channels, init_channels, kernel_size=4, stride=2, padding=1):\n",
    "        super(Discriminator, self).__init__()\n",
    "        #TODO: discriminator network\n",
    "    \n",
    "    def forward(self, input):\n",
    "        #TODO: forward\n",
    "        return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator Network\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, img_channels, target_channels, init_size, kernel_size=4, stride=2, padding=1):\n",
    "        super(Generator, self).__init__()\n",
    "        #TODO: generator network\n",
    "    def forward(self, input):\n",
    "        #TODO: forward\n",
    "        return input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom weights initialization called on netG and netD\n",
    "def weights_init(m):\n",
    "    #TODO: weight initialization\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_conv_layers = 64\n",
    "noise_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator(\n",
      "  (main): Sequential(\n",
      "    (0): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace)\n",
      "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): LeakyReLU(negative_slope=0.2, inplace)\n",
      "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): LeakyReLU(negative_slope=0.2, inplace)\n",
      "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): LeakyReLU(negative_slope=0.2, inplace)\n",
      "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1))\n",
      "    (12): Sigmoid()\n",
      "  )\n",
      ")\n",
      "Generator(\n",
      "  (main): Sequential(\n",
      "    (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace)\n",
      "    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace)\n",
      "    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): ReLU(inplace)\n",
      "    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): ReLU(inplace)\n",
      "    (12): ConvTranspose2d(64, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (13): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Create networks and apply weight initializers\n",
    "disc = Discriminator(img_channels, init_conv_layers).to(device)\n",
    "disc.apply(weights_init)\n",
    "print(disc)\n",
    "\n",
    "gen = Generator(img_channels, init_conv_layers, noise_size).to(device)\n",
    "gen.apply(weights_init)\n",
    "print(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.BCELoss()\n",
    "\n",
    "batch_size = 32\n",
    "lr = 0.0002\n",
    "example_noise = torch.randn(batch_size, noise_size, 1, 1)\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "\n",
    "# setup optimizer\n",
    "optimizer_disc = optim.Adam(disc.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "optimizer_gen = optim.Adam(gen.parameters(), lr=lr, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = torch.utils.data.DataLoader(mnist_data, batch_size=batch_size, shuffle=True)\n",
    "for i, data in enumerate(loader):\n",
    "    #TODO: Errors and optimization steps\n",
    "    \n",
    "    ####### Discriminator error ######\n",
    "    disc.zero_grad()\n",
    "    \n",
    "    # Get batch data\n",
    "   \n",
    "    # Real data error\n",
    "    \n",
    "    # Generate fake data\n",
    "    \n",
    "    # Fake data error\n",
    "    \n",
    "    # Optimization step\n",
    "   \n",
    "    ###### Generator error ######\n",
    "    gen.zero_grad()\n",
    "    \n",
    "    # Generator error (labels are opposite of discriminator labels)\n",
    "   \n",
    "    if i % 100 == 0:\n",
    "        #TODO: print losses\n",
    "        pass \n",
    "    \n",
    "    if i % 500 == 0:\n",
    "        #TODO: show generator examples\n",
    "        pass\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_tensor_imgs(gen(noise).detach(), normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecturas\n",
    "* [An intuitive guide to Convolutional Neural Networks](https://medium.freecodecamp.org/an-intuitive-guide-to-convolutional-neural-networks-260c2de0a050)\n",
    "* [A Beginner's Guide to Generative Adversarial Networks (GANs)](https://skymind.ai/wiki/generative-adversarial-network-gan)\n",
    "* [An intuitive introduction to Generative Adversarial Networks (GANs)](https://medium.freecodecamp.org/an-intuitive-introduction-to-generative-adversarial-networks-gans-7a2264a81394)\n",
    "\n",
    "## Referencia general\n",
    "* [Deep Learning](https://www.deeplearningbook.org/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
